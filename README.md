# Multimodal-Fusion-3D-segmentation
Multi-modal Sensor Fusion for 3D segmentation: A Survey

This repo is used for recording, tracking, and benchmarking several recent multimodal 3D segmentation methods, as
a supplement to our servey.
If you find any work missing or have any suggestions (papers, implementations and other resources), feel free to
pull requests. We will add the missing papers to this repo ASAP.

ðŸ”¥Highlight!!
[1]. Our study covers the latest (2020-2024) progress in the field of deep learning for multimodal 3D point cloud segmentation. It goes beyond existing papers and covers the latest multimodal point cloud segmentation methods that have not been systematically summarized and widely discussed.
[2]. We have perfected a comprehensive classification method, including symmetric and asymmetric methods, and on this basis, it is subdivided into 7 subcategories based on data, features, and results as shown in Figure [3]. Our paperâ€™s classification is relatively objective and clear, and its coverage is relatively comprehensive. By combining these previously unexplored methods, we solved the significant gaps in the existing review papers.
[4]. We comprehensively compare existing methods on current mainstream datasets and briefly analyze and discuss current multimodal 3D segmentation models. This enables readers to grasp the various methods in the context of their specific advantages and applications.
[5]. Our paper includes a comprehensive discussion of the current challenges in the field and provides profound directions for future research.
